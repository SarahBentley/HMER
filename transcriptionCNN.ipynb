{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1_beeyOQi2Ljej0nj8NkHXni6vcsGJX6J","authorship_tag":"ABX9TyMahOo1Zk4tDLa1xc2pGM3z"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Dependencies"],"metadata":{"id":"DndRPf3C31-b"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wkwz6Yvw1W6g","executionInfo":{"status":"ok","timestamp":1715263988872,"user_tz":240,"elapsed":11495,"user":{"displayName":"Camila M-H","userId":"05500492683042048043"}},"outputId":"94036a2b-284e-4d94-96fa-0b52c672632b"},"outputs":[{"output_type":"stream","name":"stdout","text":["2.15.0\n"]}],"source":["import tensorflow as tf\n","print(tf.__version__)\n","import keras\n","from keras import layers\n","from keras import models\n","from tensorflow.keras.layers import Input, Concatenate, Dense, LSTM, Embedding\n","from tensorflow.keras.models import Model\n","import pandas as pd\n","import numpy as np"]},{"cell_type":"markdown","source":["# Import Data"],"metadata":{"id":"8XHgug-D5TUv"}},{"cell_type":"code","source":["# Mount drive and make folders\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","training_csv_path =  '/content/drive/MyDrive/6.8301 Final Project/data/datasets/transcription/train.csv'\n","test_csv_path = '/content/drive/MyDrive/6.8301 Final Project/data/datasets/transcription/test.csv'\n","val_csv_path = '/content/drive/MyDrive/6.8301 Final Project/data/datasets/transcription/val.csv'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CZdTppZB5WDN","executionInfo":{"status":"ok","timestamp":1715195932983,"user_tz":240,"elapsed":1092,"user":{"displayName":"Camila M-H","userId":"05500492683042048043"}},"outputId":"bc905de9-0715-4b3b-ccaf-20b27df8b8a9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["# Read CSV file\n","train_df = pd.read_csv(training_csv_path)\n","\n","# Extract labels from DataFrame\n","target_latex_string = target_latex_string = np.expand_dims(train_df['latex'].values, axis=1)\n","\n","# Find the maximum sequence length in the 'visible_latex_chars' column\n","max_sequence_length = max(len(eval(seq)) for seq in train_df['visible_char_map'])\n","\n","# Initialize an empty numpy arrays to store inputs\n","visible_chars_map  = np.zeros((len(train_df), max_sequence_length))\n","xmins = np.zeros((len(train_df), max_sequence_length))\n","xmaxs = np.zeros((len(train_df), max_sequence_length))\n","ymins = np.zeros((len(train_df), max_sequence_length))\n","ymaxs = np.zeros((len(train_df), max_sequence_length))\n","\n","# Iterate over each row in the DataFrame and unpack arrays\n","for i, latex_num in enumerate(train_df['visible_char_map']):\n","    # Split the string into individual characters\n","    latex_chars = eval(latex_num)\n","    # Fill the array with the characters, truncating or padding as needed\n","    visible_chars_map[i, :len(latex_chars)] = latex_chars[:max_sequence_length]\n","\n","\n","# Iterate over each row in the CSV and fill the numpy array\n","for i, row in enumerate(train_df['xmins']):\n","    # Parse the array from the string\n","    array_values = eval(row)\n","    # Fill the numpy array with the array values\n","    xmins[i, :len(array_values)] = array_values\n","\n","for i, row in enumerate(train_df['xmaxs']):\n","    # Parse the array from the string\n","    array_values = eval(row)\n","    # Fill the numpy array with the array values\n","    xmaxs[i, :len(array_values)] = array_values\n","\n","for i, row in enumerate(train_df['ymins']):\n","    # Parse the array from the string\n","    array_values = eval(row)\n","    # Fill the numpy array with the array values\n","    ymins[i, :len(array_values)] = array_values\n","\n","for i, row in enumerate(train_df['ymaxs']):\n","    # Parse the array from the string\n","    array_values = eval(row)\n","    # Fill the numpy array with the array values\n","    ymaxs[i, :len(array_values)] = array_values\n","\n","unique_chars = set()\n","for chars in visible_chars_map:\n","    unique_chars.update(chars)\n","num_chars = len(unique_chars)\n","\n","unique_labels = np.unique(target_latex_string)\n","num_classes = len(unique_labels)\n","\n","print(\"visible_chars_map:\", visible_chars_map.shape)\n","print(\"xmins_array:\", xmins.shape)\n","print(\"xmaxs_array:\", xmaxs.shape)\n","print(\"ymins_array:\", ymins.shape)\n","print(\"ymaxs_array:\", ymaxs.shape)\n","print(\"target_latex_string:\", target_latex_string.shape)\n","\n","print(\"visible_chars_map:\", visible_chars_map[:5])\n","print(\"xmins:\", xmins[:5])\n","print(\"xmaxs:\", xmaxs[:5])\n","print(\"ymins:\", ymins[:5])\n","print(\"ymaxs:\", ymaxs[:5])\n","print(\"target_latex_string:\", target_latex_string[:5])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4eFhogrR6ow3","executionInfo":{"status":"ok","timestamp":1715197939818,"user_tz":240,"elapsed":2273,"user":{"displayName":"Camila M-H","userId":"05500492683042048043"}},"outputId":"d5de1010-e32b-4f7b-ed93-0b9d7f08d145"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["visible_chars_map: (8000, 64)\n","xmins_array: (8000, 64)\n","xmaxs_array: (8000, 64)\n","ymins_array: (8000, 64)\n","ymaxs_array: (8000, 64)\n","target_latex_string: (8000, 1)\n","visible_chars_map: [[43. 71. 68. 75. 33. 26.  7.  7. 54. 54. 68. 12. 37. 26. 28. 33. 80. 34.\n","  68. 21.  7. 54. 54. 68. 12. 78. 68. 26. 68. 76. 33. 68. 21.  0.  0.  0.\n","   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n","   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"," [71. 25. 75. 28. 34.  7. 28. 40. 25. 31. 26. 35. 25. 37. 26. 28. 25. 28.\n","  34. 25. 35. 26. 28. 33. 25. 37.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n","   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n","   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"," [55. 71. 68. 75. 35. 26.  7.  7. 38. 68. 26. 34. 78. 68.  0.  0.  0.  0.\n","   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n","   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n","   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"," [71. 58. 75. 32. 26. 55. 79. 12. 35. 26. 58. 78. 58. 21.  0.  0.  0.  0.\n","   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n","   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n","   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"," [71. 59. 75. 10.  7. 72. 32. 40. 59. 72. 36. 33. 33.  7. 72. 36. 31. 33.\n","  72. 33. 33. 59.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n","   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n","   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n","xmins: [[0.0144657  0.07326178 0.06672888 0.0839944  0.11712552 0.13579095\n","  0.1955203  0.24591694 0.24731685 0.23238451 0.25664956 0.30004666\n","  0.37050863 0.41250583 0.45730285 0.50909939 0.57722818 0.74848343\n","  0.81147923 0.86700887 0.19832011 0.21791881 0.20111993 0.22585161\n","  0.26971535 0.35837611 0.48016799 0.52589827 0.57442837 0.6430238\n","  0.78908073 0.85254316 0.90900607 0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.        ]\n"," [0.00480769 0.15865385 0.22435897 0.30128205 0.33894231 0.40304487\n","  0.45592949 0.4911859  0.55769231 0.59214744 0.64823718 0.6875\n","  0.74759615 0.78044872 0.85817308 0.89342949 0.95112179 0.50560897\n","  0.54086538 0.61217949 0.6474359  0.71714744 0.75641026 0.7900641\n","  0.8525641  0.88221154 0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.        ]\n"," [0.00554939 0.10987791 0.3063263  0.38068812 0.47835738 0.56159822\n","  0.72697003 0.66703663 0.84239734 0.77802442 0.83018868 0.89234184\n","  0.73806881 0.94228635 0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.        ]\n"," [0.00153022 0.19969396 0.24254017 0.30221882 0.31063504 0.42081102\n","  0.496557   0.58990054 0.61361897 0.67712318 0.72915073 0.77276205\n","  0.91354246 0.9648049  0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.        ]\n"," [0.00210379 0.1858345  0.22440393 0.27349229 0.34291725 0.39901823\n","  0.5483871  0.58204769 0.64375877 0.39340813 0.54978962 0.58274895\n","  0.64726508 0.66970547 0.73001403 0.86605891 0.89060309 0.94880785\n","  0.73211781 0.86886396 0.8997195  0.957223   0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.        ]]\n","xmaxs: [[0.04713019 0.15725618 0.08306113 0.10872608 0.13205786 0.15398973\n","  0.99486701 0.28511433 0.26691554 0.25431638 0.2795147  0.36677555\n","  0.40083994 0.45076995 0.50303313 0.54269715 0.75781615 0.77228185\n","  0.84694354 0.92300513 0.23891741 0.24078395 0.22025198 0.24918339\n","  0.34437704 0.43723752 0.51143257 0.56882874 0.61035931 0.76761549\n","  0.80867942 0.89034064 0.96313579 0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.        ]\n"," [0.13461538 0.17788462 0.28044872 0.33092949 0.37259615 0.99038462\n","  0.48237179 0.52323718 0.57772436 0.60576923 0.67948718 0.71634615\n","  0.76602564 0.81410256 0.89423077 0.91746795 0.96794872 0.53445513\n","  0.56891026 0.63060897 0.67788462 0.75080128 0.78285256 0.82291667\n","  0.87339744 0.91185897 0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.        ]\n"," [0.09877913 0.30743618 0.35738069 0.45172031 0.53940067 0.63596004\n","  0.97780244 0.98335183 0.89789123 0.81798002 0.87791343 0.95338513\n","  0.87014428 0.97891232 0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.        ]\n"," [0.18133129 0.24024484 0.29533282 0.30986993 0.35960214 0.489671\n","  0.55700077 0.60902831 0.6641163  0.72609028 0.76970161 0.88752869\n","  0.95485845 0.98087223 0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.        ]\n"," [0.17321178 0.22159888 0.26437588 0.3197756  0.70336606 0.54067321\n","  0.57784011 0.60939691 0.69004208 0.53506311 0.57643759 0.61851332\n","  0.68934081 0.9628331  0.86465638 0.89200561 0.91865358 0.98316971\n","  0.87447405 0.8941094  0.92987377 0.99789621 0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.        ]]\n","ymins: [[0.3163482  0.23354565 0.53927813 0.57324841 0.52653928 0.45435244\n","  0.40127389 0.19532909 0.00424628 0.22080679 0.27813163 0.01698514\n","  0.06369427 0.11252654 0.19320594 0.07006369 0.13375796 0.04458599\n","  0.1507431  0.09129512 0.61358811 0.42250531 0.63481953 0.70063694\n","  0.47133758 0.507431   0.57961783 0.59872611 0.60721868 0.64543524\n","  0.59023355 0.67091295 0.61783439 0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.        ]\n"," [0.07073955 0.37620579 0.49196141 0.52411576 0.4437299  0.50482315\n","  0.30546624 0.23151125 0.25401929 0.05144695 0.31189711 0.31189711\n","  0.32797428 0.14469453 0.40192926 0.48231511 0.414791   0.76527331\n","  0.67202572 0.7073955  0.54983923 0.77170418 0.85209003 0.77813505\n","  0.79421222 0.64308682 0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.        ]\n"," [0.71343284 0.31940299 0.71343284 0.80895522 0.65373134 0.49552239\n","  0.54626866 0.25970149 0.02686567 0.33134328 0.32238806 0.29850746\n","  0.58208955 0.6358209  0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.        ]\n"," [0.31045752 0.69607843 0.83986928 0.7254902  0.53594771 0.44117647\n","  0.22875817 0.2254902  0.23202614 0.26470588 0.20915033 0.00653595\n","  0.0130719  0.24183007 0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.        ]\n"," [0.04577465 0.52816901 0.65140845 0.57394366 0.48239437 0.00352113\n","  0.21126761 0.21126761 0.03169014 0.52112676 0.68661972 0.70422535\n","  0.50704225 0.48943662 0.0528169  0.21830986 0.25       0.06690141\n","  0.52112676 0.69366197 0.69366197 0.52816901 0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.        ]]\n","ymaxs: [[0.42250531 0.4670913  0.63481953 0.61358811 0.63481953 0.53927813\n","  0.60721868 0.2059448  0.19532909 0.4118896  0.40552017 0.33757962\n","  0.2866242  0.2866242  0.21443737 0.30573248 0.33757962 0.18259023\n","  0.33333333 0.45435244 0.63057325 0.58386412 0.81104034 0.82590234\n","  0.86624204 0.74522293 0.76857749 0.77282378 0.80467091 0.82802548\n","  0.73248408 0.85562633 0.98301486 0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.        ]\n"," [0.36012862 0.53376206 0.55948553 0.5562701  0.64630225 0.65916399\n","  0.33440514 0.41800643 0.42765273 0.24115756 0.44694534 0.53054662\n","  0.48231511 0.34083601 0.55305466 0.51125402 0.58842444 0.80385852\n","  0.8488746  0.88745981 0.76527331 0.92604502 0.88424437 0.98392283\n","  0.97749196 0.83601286 0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.        ]\n"," [0.9761194  0.62686567 0.98208955 0.95223881 0.95522388 0.72238806\n","  0.58507463 0.29253731 0.2119403  0.51940299 0.47164179 0.54925373\n","  0.82089552 0.82985075 0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.        ]\n"," [0.96405229 0.95424837 0.99673203 0.94117647 0.66993464 0.71895425\n","  0.51960784 0.51633987 0.49673203 0.4248366  0.46405229 0.26797386\n","  0.29738562 0.54248366 0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.        ]\n"," [0.60211268 0.78169014 0.75       0.6971831  0.52816901 0.47535211\n","  0.42957746 0.43309859 0.28169014 0.95774648 0.96478873 0.91549296\n","  0.77112676 0.51760563 0.45070423 0.46126761 0.42605634 0.30985915\n","  0.97183099 0.89084507 0.89084507 0.78521127 0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.        ]]\n","target_latex_string: [['=\\\\lim_{x\\\\to2^{+}}\\\\frac{\\\\frac{d}{dx}\\\\left(6+-2\\\\tan^{3}{x}\\\\right)}{\\\\frac{d}{dx}\\\\left(\\\\sin{x}+x\\\\cos^{2}{x}\\\\right)}']\n"," ['\\\\lim_{\\\\theta\\\\to-3}\\\\frac{-9\\\\theta^{0}+4\\\\theta^{6}+-\\\\theta}{-3\\\\theta^{4}+-2\\\\theta^{6}}']\n"," ['e^{\\\\lim_{x\\\\to4^{+}}\\\\frac{\\\\frac{7}{x+3}}{\\\\sin{x}}}']\n"," ['\\\\lim_{h\\\\to1^{+}}e^{\\\\ln{\\\\left(4+h^{\\\\sin{h}}\\\\right)}}']\n"," ['\\\\lim_{k\\\\to\\\\infty}\\\\frac{\\\\log_{19}{k}}{\\\\log_{52}{2}}\\\\frac{\\\\log_{50}{2}}{\\\\log_{22}{k}}']]\n"]}]},{"cell_type":"markdown","source":["# Model Architecture"],"metadata":{"id":"A4zpkdOH5GsY"}},{"cell_type":"code","source":["# Input layers for visible characters and bounding box coordinates\n","visible_chars_input = Input(shape=(64,))  # Assuming each visible character is represented as a sequence of floats\n","\n","# Process bounding box coordinates\n","xmins_input = Input(shape=(64,))\n","xmaxs_input = Input(shape=(64,))\n","ymins_input = Input(shape=(64,))\n","ymaxs_input = Input(shape=(64,))\n","bbox_features = Concatenate()([xmins_input, xmaxs_input, ymins_input, ymaxs_input])\n","bbox_features = Dense(64, activation='relu')(bbox_features)\n","\n","# Combine visible characters and bbox features\n","combined_features = Concatenate()([visible_chars_input, bbox_features])\n","\n","# Embedding layer for visible characters\n","embedding_layer = Embedding(input_dim=num_chars, output_dim=64)(combined_features)  # Adjust output_dim based on your requirements\n","\n","# RNN for sequence modeling\n","rnn_output = LSTM(128, return_sequences=True)(embedding_layer)  # Return sequences\n","\n","# Output layer\n","output = Dense(num_chars, activation='softmax')(rnn_output)  # Output at each timestep"],"metadata":{"id":"_33ao8JO5LPC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Create the model"],"metadata":{"id":"FVwbuP4w-Zde"}},{"cell_type":"code","source":["# Define the model\n","model = Model(inputs=[visible_chars_input, xmins_input, xmaxs_input, ymins_input, ymaxs_input], outputs=output)\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Display the model summary\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5OZRYI0p-ceG","executionInfo":{"status":"ok","timestamp":1715198103060,"user_tz":240,"elapsed":158,"user":{"displayName":"Camila M-H","userId":"05500492683042048043"}},"outputId":"d666e2fb-9c93-4f09-9efd-81e35d56fe89"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_16\"\n","__________________________________________________________________________________________________\n"," Layer (type)                Output Shape                 Param #   Connected to                  \n","==================================================================================================\n"," input_2 (InputLayer)        [(None, 64)]                 0         []                            \n","                                                                                                  \n"," input_3 (InputLayer)        [(None, 64)]                 0         []                            \n","                                                                                                  \n"," input_4 (InputLayer)        [(None, 64)]                 0         []                            \n","                                                                                                  \n"," input_5 (InputLayer)        [(None, 64)]                 0         []                            \n","                                                                                                  \n"," concatenate_36 (Concatenat  (None, 256)                  0         ['input_2[0][0]',             \n"," e)                                                                  'input_3[0][0]',             \n","                                                                     'input_4[0][0]',             \n","                                                                     'input_5[0][0]']             \n","                                                                                                  \n"," input_1 (InputLayer)        [(None, 64)]                 0         []                            \n","                                                                                                  \n"," dense_34 (Dense)            (None, 64)                   16448     ['concatenate_36[0][0]']      \n","                                                                                                  \n"," concatenate_37 (Concatenat  (None, 128)                  0         ['input_1[0][0]',             \n"," e)                                                                  'dense_34[0][0]']            \n","                                                                                                  \n"," embedding_18 (Embedding)    (None, 128, 64)              3520      ['concatenate_37[0][0]']      \n","                                                                                                  \n"," lstm (LSTM)                 (None, 128, 128)             98816     ['embedding_18[0][0]']        \n","                                                                                                  \n"," dense_35 (Dense)            (None, 128, 55)              7095      ['lstm[0][0]']                \n","                                                                                                  \n","==================================================================================================\n","Total params: 125879 (491.71 KB)\n","Trainable params: 125879 (491.71 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["# Train the model\n"],"metadata":{"id":"G7ebgWMVp2HG"}},{"cell_type":"code","source":["# Train the model\n","model.fit([visible_chars_map, xmins, xmaxs, ymins, ymaxs], visible_chars_map, epochs=10, batch_size=32, validation_split=0.2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":633},"id":"nX4AfGIDp8wk","executionInfo":{"status":"error","timestamp":1715196403962,"user_tz":240,"elapsed":553,"user":{"displayName":"Camila M-H","userId":"05500492683042048043"}},"outputId":"6b3b0221-13de-4d66-f836-89509a96b981"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n"]},{"output_type":"error","ename":"ValueError","evalue":"in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model_15\" is incompatible with the layer: expected shape=(None, 64), found shape=(32, 2304)\n","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-47-a45557c0a06f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     {'visible_chars_input': visible_latex_chars_encoded, 'xmins_input': xmins, 'xmaxs_input': xmaxs,\n\u001b[1;32m      3\u001b[0m      'ymins_input': ymins, 'ymaxs_input': ymaxs},\n\u001b[1;32m      4\u001b[0m     \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_latex_string\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model_15\" is incompatible with the layer: expected shape=(None, 64), found shape=(32, 2304)\n"]}]}]}